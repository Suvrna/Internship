{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e16775a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The current url is :  https://www.amazon.in/\n",
      "Exception raised :  Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6B4A152A2+57122]\n",
      "\t(No symbol) [0x00007FF6B498EA92]\n",
      "\t(No symbol) [0x00007FF6B485E3AB]\n",
      "\t(No symbol) [0x00007FF6B4897D3E]\n",
      "\t(No symbol) [0x00007FF6B4897E2C]\n",
      "\t(No symbol) [0x00007FF6B48D0B67]\n",
      "\t(No symbol) [0x00007FF6B48B701F]\n",
      "\t(No symbol) [0x00007FF6B48CEB82]\n",
      "\t(No symbol) [0x00007FF6B48B6DB3]\n",
      "\t(No symbol) [0x00007FF6B488D2B1]\n",
      "\t(No symbol) [0x00007FF6B488E494]\n",
      "\tGetHandleVerifier [0x00007FF6B4CBEF82+2849794]\n",
      "\tGetHandleVerifier [0x00007FF6B4D11D24+3189156]\n",
      "\tGetHandleVerifier [0x00007FF6B4D0ACAF+3160367]\n",
      "\tGetHandleVerifier [0x00007FF6B4AA6D06+653702]\n",
      "\t(No symbol) [0x00007FF6B499A208]\n",
      "\t(No symbol) [0x00007FF6B49962C4]\n",
      "\t(No symbol) [0x00007FF6B49963F6]\n",
      "\t(No symbol) [0x00007FF6B49867A3]\n",
      "\tBaseThreadInitThunk [0x00007FF8512926AD+29]\n",
      "\tRtlUserThreadStart [0x00007FF85340AA68+40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. Write a python program which searches all the product under a particular product from www.amazon.in. \n",
    "#The product to be searched will be taken as input from user. \n",
    "#For e.g. If user input is ‘guitar’. Then search for guitars.\n",
    "\n",
    "#2. update scrap data in Data frame.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage https://www.shine.com/\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.amazon.in\"\n",
    "    driver.get(url)\n",
    "\n",
    "    #WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, \"_1LKTO3\")))\n",
    "    \n",
    "    WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH,\"//input[@ID='twotabsearchtextbox']\")))\n",
    "    searchTxt=driver.find_element(By.XPATH,\"//input[@ID='twotabsearchtextbox']\")\n",
    "    print(searchTxt.text)\n",
    "\n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #Get new URL to fetch list as per search.\n",
    "    get_url = driver.current_url\n",
    "    print(\"The current url is : \",str(get_url))\n",
    "    \n",
    "    #Then scrape the data for the product results you get.\n",
    "    page=requests.get(get_url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    #scraping data on search text.\n",
    "    brandData=[]\n",
    "    ratingData=[]\n",
    "    offerData=[]\n",
    "    deliveryData=[]\n",
    "        \n",
    "    for i in range(2):\n",
    "        brandList=driver.find_elements(By.XPATH,\"//div[@id='search']/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[1]/h2/a/span\")\n",
    "        ratingList=driver.find_elements(By.XPATH,\"//div[@id='search']/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[2]/div[1]/span[1]/span[1]\")\n",
    "        offerList =driver.find_elements(By.XPATH,\"//div[@id='search']/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[3]/div[2]/a/span/span[2]/span[2]\")\n",
    "        deliveryList=driver.find_elements(By.XPATH,\"//div[@id='search']/div[1]/div[1]/div/span[1]/div[1]/div[3]/div/div/div/div/div/div/div[2]/div[4]/div/div[1]/span[2]/span[2]\")\n",
    "    \n",
    "        for j in brandList:\n",
    "            brandData.append(j.text)\n",
    "\n",
    "        for k in ratingList:\n",
    "            ratingData.append(k.text)\n",
    "\n",
    "        for l in offerList:\n",
    "            offerData.append(l.text)\n",
    "        \n",
    "        for t in deliveryList:\n",
    "            deliveryData.append(t.text)\n",
    "        \n",
    "        WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.XPATH, \"/html/body/div[1]/div[2]/div[1]/div[1]/div/span[1]/div[1]/div[66]/div/div/span/a[3]\")))\n",
    "        searchNxt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[1]/div/span[1]/div[1]/div[66]/div/div/span/a[3]\")\n",
    "        searchNxt.click()\n",
    "       \n",
    "        driver.implicitly_wait(3) # seconds\n",
    "        \n",
    "        #Get new URL to fetch list as per search.\n",
    "        get_url = driver.current_url\n",
    "        print(\"The current url is : \",str(get_url))\n",
    "    \n",
    "    #print data to check\n",
    "    print(len(brandData),\"\\n\",len(ratingData),\"\\n\",len(offerData),\"\\n\",len(deliveryData))\n",
    "    #print(rateData[:100],\"\\n\",reviewData[:100],\"\\n\",fullreviewData[:100])      \n",
    "\n",
    "    # some error is occ        \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b182738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a4971b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current url is :  https://www.google.com/search?q=fruits&sca_esv=561868494&tbm=isch&source=hp&biw=1036&bih=659&ei=FpjxZN-5Ib6xwPAPy72T8AU&iflsig=AD69kcEAAAAAZPGmJjwF1p1vSDPWptQxHd4Wom5M90QI\n",
      "The current url is :  https://www.google.com/search?q=cars&tbm=isch&ved=2ahUKEwjP0cf69oiBAxV8FhAIHas2CqoQ2-cCegQIABAA&bih=659&biw=1036\n",
      "The current url is :  https://www.google.com/search?q=Machine+Learning&tbm=isch&ved=2ahUKEwjc8O799oiBAxW8MhAIHVyICbAQ2-cCegQIABAA&bih=659&biw=1036\n"
     ]
    }
   ],
   "source": [
    "#3. Write a python program to access the search bar and search button on images.google.com \n",
    "#and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage images.google.com\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://images.google.com\"\n",
    "    driver.get(url)\n",
    "\n",
    "    searchImg = driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "    WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, \"gLFyf\"))) \n",
    "    searchImg.send_keys('fruits')\n",
    "    \n",
    "    #3. Then click the search button.\n",
    "    search_btn = driver.find_element(By.CLASS_NAME,\"Tg7LZd\")\n",
    "    #search_btn.click()\n",
    "    search_btn.submit()\n",
    "\n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(3) # seconds\n",
    "\n",
    "    #other data to search\n",
    "    searchData=['cars','Machine Learning','Cakes']\n",
    "    \n",
    "    for d in searchData:\n",
    "        #Get new URL to fetch list as per search.\n",
    "        get_url = driver.current_url\n",
    "        print(\"The current url is : \",str(get_url))\n",
    "    \n",
    "        #4. Then scrape the data for the jobs results you get.\n",
    "        page=requests.get(get_url)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "        \n",
    "        #write a code to scrap data \n",
    "        \n",
    "        #search next images from data list\n",
    "        searchImg = driver.find_element(By.CLASS_NAME,\"og3lId\")\n",
    "        WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.CLASS_NAME, \"og3lId\"))) \n",
    "        searchImg.clear()\n",
    "        searchImg.send_keys(d) \n",
    "            \n",
    "        #3. Then click the search button.\n",
    "        search_btn = driver.find_element(By.CLASS_NAME,\"rCGXm\")\n",
    "        #search_btn.click()\n",
    "        search_btn.submit()\n",
    "        \n",
    "        # set implicit wait time\n",
    "        driver.implicitly_wait(3) # seconds\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f758d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      " 14 \n",
      " 0 \n",
      " 1 \n",
      " 1 \n",
      " 1 \n",
      " 1 \n",
      " 9\n",
      "['OnePlus Nord (Gray Onyx, 64 GB)', 'OnePlus Nord (Blue Marble, 128 GB)', 'OnePlus Nord (Gray Onyx, 128 GB)', 'OnePlus Nord (Blue Marble, 64 GB)', 'OnePlus Nord (Blue Marble, 256 GB)', 'OnePlus Nord (Gray Onyx, 256 GB)', 'OnePlus Nord CE 2 5G (Gray Mirror, 128 GB)', 'OnePlus Nord CE 2 5G (Bahama Blue, 128 GB)', 'OnePlus Nord CE 2 5G (Gray Mirror, 128 GB)'] \n",
      " ['4.2', '4.1', '4.1', '4.2', '4', '4', '4.3', '4.3', '4.2', '4.2', '4.3', '4.2', '4.1', '4'] \n",
      " [] \n",
      " ['6 GB RAM | 64 GB ROM'] \n",
      " ['16.36 cm (6.44 inch) Full HD+ Display'] \n",
      " ['48MP + 8MP | 32MP + 8MP Dual Front Camera'] \n",
      " ['4115 mAh Battery'] \n",
      " ['https://www.flipkart.com/oneplus-nord-gray-onyx-64-gb/p/itm49f817b591982?pid=MOBFUE5H57THFNVJ&lid=LSTMOBFUE5H57THFNVJQKJ846&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5H57THFNVJ.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-blue-marble-128-gb/p/itm3f93c90430130?pid=MOBFUE5JWYDZX6HX&lid=LSTMOBFUE5JWYDZX6HXVKC6BE&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5JWYDZX6HX.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-gray-onyx-128-gb/p/itm3f93c90430130?pid=MOBFUE5HW4XUUGBN&lid=LSTMOBFUE5HW4XUUGBNU9KEOL&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_3&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5HW4XUUGBN.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-blue-marble-64-gb/p/itm49f817b591982?pid=MOBFUE5N7KAGZHHC&lid=LSTMOBFUE5N7KAGZHHCUOBN3W&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_4&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5N7KAGZHHC.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-blue-marble-256-gb/p/itm3f93c90430130?pid=MOBFUE5HUU5ZYGRY&lid=LSTMOBFUE5HUU5ZYGRY4ZWZZN&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_5&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5HUU5ZYGRY.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-gray-onyx-256-gb/p/itm49f817b591982?pid=MOBFUE5GGWHFC37J&lid=LSTMOBFUE5GGWHFC37JNXZLYZ&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_6&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBFUE5GGWHFC37J.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-ce-2-5g-gray-mirror-128-gb/p/itm2a9883679c57c?pid=MOBGDHWMFQBKFV5F&lid=LSTMOBGDHWMFQBKFV5FAU6CVT&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_7&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBGDHWMFQBKFV5F.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-ce-2-5g-bahama-blue-128-gb/p/itm2a9883679c57c?pid=MOBGJMUH64MTF6PK&lid=LSTMOBGJMUH64MTF6PKEYGNXF&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_8&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBGJMUH64MTF6PK.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e', 'https://www.flipkart.com/oneplus-nord-ce-2-5g-gray-mirror-128-gb/p/itme3c94dc3fc910?pid=MOBGJMUHX7ACJ44Z&lid=LSTMOBGJMUHX7ACJ44ZUMG0PU&marketplace=FLIPKART&q=Oneplus+Nord%2C+pixel+4A&store=tyy%2F4io&srno=s_1_9&otracker=search&otracker1=search&fm=organic&iid=6feaab84-e1cb-4d8e-b42c-54a373e14a29.MOBGJMUHX7ACJ44Z.SEARCH&ppt=hp&ppn=homepage&ssid=jyjzfyayu80000001693565417620&qH=51e22a8c2f127b5e']\n"
     ]
    }
   ],
   "source": [
    "#4 Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) \n",
    "#on www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "#Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "#“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. \n",
    "#Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV.\n",
    "\n",
    "\n",
    "#import required libraray.\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    #1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.flipkart.com/\"\n",
    "    driver.get(url)\n",
    "    #driver.maximize_window()\n",
    "\n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #2. Enter “Oneplus Nord, pixel 4A” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "    search_prod = driver.find_element(By.CLASS_NAME,\"_3704LK\")   #Pke_EE \n",
    "    search_prod.send_keys('Oneplus Nord, pixel 4A')\n",
    "\n",
    "    search = driver.find_element(By.CLASS_NAME,\"L0Z3Pu\") # #_2iLD__\n",
    "    search.click()\n",
    "\n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #list for Brand, Product_Description, Price, offer\n",
    "    brandData=[]\n",
    "    priceData=[]\n",
    "    ratingData=[]\n",
    "    ramData=[]\n",
    "    screenData=[]\n",
    "    camData=[]\n",
    "    batteryData=[]\n",
    "    urlData=[]\n",
    "    \n",
    "    brandName=driver.find_elements(By.XPATH,\"//div[@class='_4rR01T']\")\n",
    "    ratinglist=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK']\")\n",
    "    pricel=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3._1_WHN1']\") \n",
    "    ramD =driver.find_elements(By.XPATH,\"//div[@id='container']/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[3]/ul/li[1]\")\n",
    "    screenD =driver.find_elements(By.XPATH,\"//div[@id='container']/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[3]/ul/li[2]\")\n",
    "    camD =driver.find_elements(By.XPATH,\"//div[@id='container']/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[3]/ul/li[3]\")\n",
    "    batteryD =driver.find_elements(By.XPATH,\"//div[@id='container']/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[3]/ul/li[4]\")\n",
    "    urlD=driver.find_elements(By.XPATH,\"//a[@class='_1fQZEK']\") \n",
    "       \n",
    "    for j in brandName:\n",
    "        brandData.append(j.text)\n",
    "\n",
    "    for k in ratinglist:\n",
    "        ratingData.append(k.text)\n",
    "\n",
    "    for l in pricel:\n",
    "        priceData.append(l.text)\n",
    "        \n",
    "    for m in ramD:\n",
    "        ramData.append(m.text)\n",
    "\n",
    "    for n in screenD:\n",
    "        screenData.append(n.text)\n",
    "        \n",
    "    for o in camD:\n",
    "        camData.append(o.text)       \n",
    "        \n",
    "    for p in batteryD:\n",
    "        batteryData.append(p.text)\n",
    "\n",
    "    for q in urlD:\n",
    "        urlData.append(q.get_attribute('href'))\n",
    "\n",
    "    #print data to check\n",
    "    print(len(brandData),\"\\n\",len(ratingData),\"\\n\",len(priceData),\"\\n\",len(ramData),\"\\n\",len(screenData),\"\\n\",len(batteryData),\"\\n\",len(camData),\"\\n\",len(urlD))\n",
    "    print(brandData,\"\\n\",ratingData,\"\\n\",priceData,\"\\n\",ramData,\"\\n\",screenData,\"\\n\",camData,\"\\n\",batteryData,\"\\n\",urlData)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f5f91c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The map is :  https://www.google.com/maps/@18.648061,73.7595417,15z?entry=ttu\n",
      "The latitude is :  18.648061\n",
      "The longitude is :  73.7595417\n"
     ]
    }
   ],
   "source": [
    "#Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps.\n",
    "\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage images.google.com\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://map.google.com\"\n",
    "    driver.get(url)\n",
    "\n",
    "    WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH,\"//input[@ID='searchboxinput']\")))\n",
    "    searchTxt=driver.find_element(By.XPATH,\"//input[@ID='searchboxinput']\")\n",
    "   # print(searchTxt.text)\n",
    "\n",
    "    # set implicit wait time\n",
    "    #driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #3. Then click the search button.\n",
    "    search_btn = driver.find_element(By.XPATH,\"/html/body/div[3]/div[8]/div[3]/div[1]/div[1]/div/div[2]/div[1]/button\")\n",
    "    search_btn.click()\n",
    "  \n",
    "    #Get new URL to fetch list as per search.\n",
    "    get_url = driver.current_url\n",
    "    print(\"The map is : \",str(get_url))       \n",
    "\n",
    "    # from url string we can extract numbers for longitutde and latitude\n",
    "    \n",
    "    latlngStr=re.findall(r'\\d+', get_url)\n",
    "\n",
    "    latStr=latlngStr[0]+\".\"+latlngStr[1]\n",
    "    logStr=latlngStr[2]+\".\"+latlngStr[3]\n",
    "    \n",
    "    print(\"The latitude is : \",latStr)   \n",
    "    print(\"The longitude is : \",logStr)   \n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fad65d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current url is :  https://www.digit.in/gaming-mart/topten/gaming-laptops/\n",
      "Best Gaming Laptops Under Rs 50,000\n",
      "Best HP Gaming Laptop in India\n",
      "Best Dell Gaming Laptop\n",
      "Best Gaming Laptops Under Rs. 60000\n",
      "Best Lenovo Gaming Laptops in India\n",
      "Best Joystick Gaming Controllers in India\n",
      "Best Mobile Game Controllers in India\n",
      "Best Gamepad Gaming Controllers in India\n",
      "Best Gaming Controllers in India\n",
      "Best PS5 Controllers in India\n",
      "Best Budget Gaming Earphones\n",
      "Best Gaming Headphones with Mic\n",
      "Best Wireless Gaming Headphones\n",
      "Best Gaming Headphones for PS4\n",
      "Best Gaming Headphones in India\n",
      "Best 4K Gaming Monitor\n",
      "Best 240Hz Gaming Monitor\n",
      "Best 1440p Gaming Monitor\n",
      "Best Gaming Monitor under 10,000\n",
      "Best Gaming Monitors in India\n",
      "Best Wireless Gaming Mouse\n",
      "Best Gaming Mouse under 2000\n",
      "Best FPS Gaming Mouse in India\n",
      "Best Gaming Mouse under 1000\n",
      "Best Gaming Mouse in India\n",
      "Best Gaming Keyboard and Mouse combos\n",
      "Best Wireless Gaming Keyboards\n",
      "Best Mechanical Gaming Keyboard\n",
      "Best RGB Keyboards for Gaming\n",
      "Best Gaming Keyboards in India\n",
      "Best SSDs for Laptops in India\n",
      "Best 1 TB NVMe SSDs for Laptop in India\n",
      "Best 500/512 GB NVMe SSDs for Laptops\n",
      "Best 250/256 GB NVMe SSDs for Laptops\n",
      "Best Shotguns in PUBG Mobile\n",
      "Best Android Games in India\n",
      "Best PC Games in India\n",
      "Best Internal PCIe Capture Cards for Gaming\n",
      "Best Capture Cards for Gaming\n",
      "Best External Capture Cards for Gaming\n",
      "Gaming Microphones for Streaming\n",
      "Best Gaming Microphones\n",
      "Best 2.1 Desktop Gaming Speakers\n",
      "Best Gaming Voice Changers\n",
      "Best Gaming Mobile Phone under ₹30,000\n",
      "Best Gaming Phones under ₹10,000 in India\n",
      "Best Gaming PC in India\n",
      "Best webcams for streaming\n",
      "Best Graphics Cards for Laptops in India\n",
      "Best Gaming Mouse Bungee\n",
      "Best Gaming Mouse Pads\n"
     ]
    }
   ],
   "source": [
    "#6. Write a program to scrap all the available details of best gaming laptops from digit.in.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage digit.in\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.digit.in/\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    #2. Then search Gaming menu.\n",
    "    search_btn = driver.find_element(By.XPATH,\"/html/body/div[2]/div/ul/li[5]/span\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    #3. Then search Gaming laptops.\n",
    "    search_btn1 = driver.find_element(By.XPATH,\"/html/body/div[2]/div/ul/li[5]/div[2]/div/div[2]/div/ul[2]/li[2]/a\")\n",
    "    search_btn1.click()\n",
    "    \n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "    \n",
    "    gamingsTitles=[]\n",
    "    \n",
    "    titles=driver.find_elements(By.XPATH,\"//ul[@CLASS='second_level']/li/a\")\n",
    "    for i in titles:\n",
    "        gamingsTitles.append(i.text)\n",
    "        print(i.text)\n",
    "    \n",
    "    #save data in dataframe.\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e.exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67225955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th Gen Intel Core i7-13700HX 16 core processor with 5.0 GHz clock speed\n",
      "17.3″ (2560 x 1440) screen, 165 Hz refresh rate\n"
     ]
    }
   ],
   "source": [
    "#6.2 Write a program to scrap all the available details of best gaming laptops from digit.in.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, JavascriptException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage digit.in\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.digit.in/\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    #2. Then search laptop menu.\n",
    "    search_btn = driver.find_element(By.XPATH,\"/html/body/div[2]/div/ul/li[2]/span\")\n",
    "    search_btn.click()\n",
    "    \n",
    "    #3. Then search best laptops.\n",
    "    search_btn1 = driver.find_element(By.XPATH,\"/html/body/div[2]/div/ul/li[2]/div[2]/div/div[1]/span[4]\")\n",
    "    search_btn1.click()\n",
    "    \n",
    "    #4. Then search Gaming laptops.\n",
    "    search_btn2 = driver.find_element(By.XPATH,\"/html/body/div[2]/div/ul/li[2]/div[2]/div/div[5]/div/div[2]/a/span\")\n",
    "    search_btn2.click()\n",
    "    \n",
    "    # set implicit wait time\n",
    "    #driver.implicitly_wait(5) # seconds\n",
    "    \n",
    "    for _ in range(20):\n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "    \n",
    "    titles=driver.find_elements(By.XPATH,\"/html/body/div[9]/div[1]/div[3]/div[2]/div[1]/div[3]/div[2]/table/tbody/tr[2]/td[3]\")\n",
    "    dispList=driver.find_elements(By.XPATH,\"/html/body/div[9]/div[1]/div[3]/div[2]/div[1]/div[3]/div[2]/table/tbody/tr[3]/td[3]\")\n",
    "      \n",
    "    #time.sleep(3)\n",
    "    \n",
    "    processData=[]\n",
    "    dispData=[]\n",
    "    \n",
    "    #note-> I dont know why only single data is coming. \n",
    "    for i in titles:\n",
    "        processData.append(i.text)\n",
    "        print(i.text)\n",
    "    \n",
    "    for i in dispList:\n",
    "        dispData.append(i.text)\n",
    "        print(i.text)\n",
    "    \n",
    "    #save data in dataframe.\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e.exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cdc6b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Bernard Arnault & family\n",
      "$211 B\n",
      "74\n",
      "France\n",
      "LVMH\n",
      "\n",
      "2\n",
      "Elon Musk\n",
      "$180 B\n",
      "51\n",
      "United States\n",
      "Tesla, SpaceX\n",
      "\n",
      "3\n",
      "Jeff Bezos\n",
      "$114 B\n",
      "59\n",
      "United States\n",
      "Amazon\n",
      "\n",
      "4\n",
      "Larry Ellison\n",
      "$107 B\n",
      "78\n",
      "United States\n",
      "Oracle\n",
      "\n",
      "5\n",
      "Warren Buffett\n",
      "$106 B\n",
      "92\n",
      "United States\n",
      "Berkshire Hathaway\n",
      "\n",
      "6\n",
      "Bill Gates\n",
      "$104 B\n",
      "67\n",
      "United States\n",
      "Microsoft\n",
      "\n",
      "7\n",
      "Michael Bloomberg\n",
      "$94.5 B\n",
      "81\n",
      "United States\n",
      "Bloomberg LP\n",
      "\n",
      "8\n",
      "Carlos Slim Helu & family\n",
      "$93 B\n",
      "83\n",
      "Mexico\n",
      "Telecom\n",
      "\n",
      "9\n",
      "Mukesh Ambani\n",
      "$83.4 B\n",
      "65\n",
      "India\n",
      "Diversified\n",
      "\n",
      "10\n",
      "Steve Ballmer\n",
      "$80.7 B\n",
      "67\n",
      "United States\n",
      "Microsoft\n",
      "\n",
      "11\n",
      "Francoise Bettencourt Meyers & family\n",
      "$80.5 B\n",
      "69\n",
      "France\n",
      "L'Oréal\n",
      "\n",
      "12\n",
      "Larry Page\n",
      "$79.2 B\n",
      "50\n",
      "United States\n",
      "Google\n",
      "\n",
      "13\n",
      "Amancio Ortega\n",
      "$77.3 B\n",
      "87\n",
      "Spain\n",
      "Zara\n",
      "\n",
      "14\n",
      "Sergey Brin\n",
      "$76 B\n",
      "49\n",
      "United States\n",
      "Google\n",
      "\n",
      "15\n",
      "Zhong Shanshan\n",
      "$68 B\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "#7. Write a python program to scrape the details for all billionaires from www.forbes.com. \n",
    "#Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException                  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage www.forbes.com\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.forbes.com/billionaires/\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    #scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”.\n",
    "  \n",
    "    rankData=[]\n",
    "    nameData=[]\n",
    "    networthData=[]\n",
    "    ageData=[]\n",
    "    industryData=[]\n",
    "    cityData=[]\n",
    "    srcData=[]\n",
    "    \n",
    "  #  titles=driver.find_elements(By.XPATH,\"//div[@CLASS='Table_dataCell__2QCve']\")\n",
    "  #  otherlist=driver.find_elements(By.XPATH,\"//div[@CLASS='Table_netWorth___L4R5 Table_dataCell__2QCve']\")\n",
    "    citylist=driver.find_elements(By.XPATH,\"//div[@CLASS='TableRow_cell__db-hv Table_cell__houv9']\")\n",
    "    \n",
    "    i=0\n",
    "    while i < 100: #len(citylist)/2:\n",
    "        rankData.append(citylist[i].text)\n",
    "        print(citylist[i].text)\n",
    "        i += 1\n",
    "        nameData.append(citylist[i].text)\n",
    "        print(citylist[i].text)\n",
    "        i += 1\n",
    "        networthData.append(citylist[i].text) \n",
    "        print(citylist[i].text)  \n",
    "        i += 1\n",
    "        ageData.append(citylist[i].text) \n",
    "        print(citylist[i].text)\n",
    "        i += 1\n",
    "        cityData.append(citylist[i].text) \n",
    "        print(citylist[i].text)\n",
    "        i += 1\n",
    "        industryData.append(citylist[i].text) \n",
    "        print(citylist[i].text)\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    dfBillnare=pd.DataFrame({}) #data is not coming in DF.\n",
    "\n",
    "    dfBillnare['Rank']=rankData[:10]\n",
    "    dfBillnare['Name']=nameData[:10]\n",
    "    dfBillnare['Net Worth']=networthData[:10]\n",
    "    dfBillnare['Age']=ageData[:10]\n",
    "    dfBillnare['Industry']=industryData[:10]\n",
    "\n",
    "    dfBillnare.head\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e.exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc50571f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoSuchWindowException' object has no attribute 'exception'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12776\\1584052125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m#WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.XPATH,\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[1]/ytd-comment-renderer/div[3]/div[2]/div[2]/ytd-expander/div/yt-formatted-string/span\")))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mauthList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[2]/ytd-comment-renderer/div[3]/div[2]/div[2]/ytd-expander/div\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=116.0.5845.141)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6F0BA52A2+57122]\n\t(No symbol) [0x00007FF6F0B1EA92]\n\t(No symbol) [0x00007FF6F09EE3AB]\n\t(No symbol) [0x00007FF6F09CE1B9]\n\t(No symbol) [0x00007FF6F0A4B417]\n\t(No symbol) [0x00007FF6F0A5E24F]\n\t(No symbol) [0x00007FF6F0A46DB3]\n\t(No symbol) [0x00007FF6F0A1D2B1]\n\t(No symbol) [0x00007FF6F0A1E494]\n\tGetHandleVerifier [0x00007FF6F0E4EF82+2849794]\n\tGetHandleVerifier [0x00007FF6F0EA1D24+3189156]\n\tGetHandleVerifier [0x00007FF6F0E9ACAF+3160367]\n\tGetHandleVerifier [0x00007FF6F0C36D06+653702]\n\t(No symbol) [0x00007FF6F0B2A208]\n\t(No symbol) [0x00007FF6F0B262C4]\n\t(No symbol) [0x00007FF6F0B263F6]\n\t(No symbol) [0x00007FF6F0B167A3]\n\tBaseThreadInitThunk [0x00007FF8BBA226AD+29]\n\tRtlUserThreadStart [0x00007FF8BC46AA68+40]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12776\\1584052125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception raised : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoSuchWindowException' object has no attribute 'exception'"
     ]
    }
   ],
   "source": [
    "#9. Write a program to extract at least \n",
    "#500 Comments, Comment upvote and time when comment was posted from any https://www.youtube.com Video.\n",
    "\n",
    "#import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, WebDriverException                  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "try:\n",
    "#1. First get the webpage www.forbes.com\n",
    "    driver = webdriver.Chrome()\n",
    "    url = \"https://www.youtube.com\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH,\"//input[@CLASS='ytd-searchbox']\")))\n",
    "    searchTxt=driver.find_element(By.XPATH,\"//input[@CLASS='ytd-searchbox']\")\n",
    "   # print(searchTxt.text)\n",
    "\n",
    "    # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #3. Then click the search button.\n",
    "    WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH,\"/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/button\")))\n",
    "    search_btn = driver.find_element(By.XPATH,\"/html/body/ytd-app/div[1]/div/ytd-masthead/div[4]/div[2]/ytd-searchbox/button\")\n",
    "    search_btn.click()\n",
    "    #search_btn.submit()\n",
    "    \n",
    "     # set implicit wait time\n",
    "    driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #yt-simple-endpoint style-scope ytd-video-renderer\n",
    "    WebDriverWait(driver,30).until(expected_conditions.element_to_be_clickable((By.XPATH,\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[1]/div[1]/div/div[1]/div/h3/a\")))\n",
    "    search=driver.find_element(By.XPATH,\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[1]/div[1]/div/div[1]/div/h3/a\")\n",
    "    search.click()\n",
    "    \n",
    "    authData=[]\n",
    "    time.sleep(30)\n",
    "    #WebDriverWait(driver,30).until(expected_conditions.presence_of_element_located((By.XPATH,\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[1]/ytd-comment-renderer/div[3]/div[2]/div[2]/ytd-expander/div/yt-formatted-string/span\")))\n",
    "    authList=driver.find_elements(By.XPATH,\"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[3]/ytd-comment-thread-renderer[2]/ytd-comment-renderer/div[3]/div[2]/div[2]/ytd-expander/div\")\n",
    "   \n",
    "    for j in authList:\n",
    "        authData.append(j.text)\n",
    "        print(j.text)\n",
    "    \n",
    "    #print(authData[:10])\n",
    "    \n",
    "    #set implicit wait time\n",
    "   #driver.implicitly_wait(5) # seconds\n",
    "\n",
    "    #Get new URL to fetch list as per search.\n",
    "    get_url = driver.current_url\n",
    "    print(\"The current url is : \",str(get_url))   \n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Exception raised : \",e.exception)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c0dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2e0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a019e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
